{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4-HZ8pbxFGW"
      },
      "source": [
        "# MoodMirror - Facial Emotion Detection\n",
        "\n",
        "In this notebook, we will train a deep learning model for facial emotion detection using the \"fer2013\" dataset from Kaggle. The model will classify facial emotions into seven categories: Angry, Disgust, Fear, Happy, Neutral, Sad, and Surprise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJoFYTilxFGZ"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries and modules\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "from keras.callbacks import TensorBoard\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBCxnGKCxFGa"
      },
      "outputs": [],
      "source": [
        "# Setting up the TensorBoard callback\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNq0VKPyxFGb"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "We will define the image dimensions, set the batch size, and specify the paths for our training and validation datasets. We will also use Keras's ImageDataGenerator to apply real-time data augmentation to the images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRmu7xkyxFGb"
      },
      "outputs": [],
      "source": [
        "# Setting image dimensions and batch size\n",
        "IMG_HEIGHT = 48\n",
        "IMG_WIDTH = 48\n",
        "batch_size = 32\n",
        "\n",
        "# Paths for training and validation datasets\n",
        "train_data_dir = \"data/train/\"\n",
        "validation_data_dir = \"data/test/\"\n",
        "\n",
        "# Creating ImageDataGenerators for training and validation datasets\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=30,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Loading training and validation data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    color_mode=\"grayscale\",\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    color_mode=\"grayscale\",\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rScU9U3jxFGc"
      },
      "source": [
        "## Visualizing Training Data\n",
        "\n",
        "Let's visualize a random image from the training dataset along with its label.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlkcOXh5xFGc"
      },
      "outputs": [],
      "source": [
        "# Displaying a random image from the training dataset\n",
        "class_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n",
        "img, label = train_generator.__next__()\n",
        "i = np.random.randint(0, img.shape[0])\n",
        "image = img[i]\n",
        "labl = class_labels[label[i].argmax()]\n",
        "plt.imshow(image[:, :, 0], cmap=\"gray\")\n",
        "plt.title(labl)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUhnVbb3xFGd"
      },
      "source": [
        "## Model Architecture\n",
        "\n",
        "We will define a sequential model with multiple convolutional layers, max-pooling layers, dropout layers, and dense layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7961WBIxFGd"
      },
      "outputs": [],
      "source": [
        "# Defining the model architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Adding layers to the model\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(48, 48, 1)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(7, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyF12JzhxFGd"
      },
      "source": [
        "## Training the Model\n",
        "\n",
        "We will train the model using the training data and validate it using the validation data. After training, we will save the model for future use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6terPV7xFGd"
      },
      "outputs": [],
      "source": [
        "# Calculating the number of images in training and test datasets\n",
        "num_train_imgs = sum([len(files) for r, d, files in os.walk(train_data_dir)])\n",
        "num_test_imgs = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
        "\n",
        "# Training the model\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=num_train_imgs // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=num_test_imgs // batch_size,\n",
        "    callbacks=[tensorboard_callback] # Adding tensorboard callback here\n",
        ")\n",
        "\n",
        "# Saving the trained model\n",
        "model.save(\"emotion_detection_model_100epochs.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orbM-e5YxFGe"
      },
      "source": [
        "## Visualizing Training Results\n",
        "\n",
        "We will plot the training and validation loss and accuracy over the epochs to visualize the performance of our model during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0_-axsOxFGe"
      },
      "outputs": [],
      "source": [
        "# Plotting training and validation loss\n",
        "plt.plot(history.history[\"loss\"], \"y\", label=\"Training loss\")\n",
        "plt.plot(history.history[\"val_loss\"], \"r\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "plt.plot(history.history[\"accuracy\"], \"y\", label=\"Training accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], \"r\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi_8c56GxFGe"
      },
      "source": [
        "## Testing the Model\n",
        "\n",
        "We will load the trained model and test its performance on a batch of validation images. We will also visualize the confusion matrix to see the accuracy of each class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM1MmnKYxFGe"
      },
      "outputs": [],
      "source": [
        "# Loading the trained model\n",
        "my_model = load_model(\"emotion_detection_model_100epochs.h5\", compile=False)\n",
        "\n",
        "# Making predictions on a batch of validation images\n",
        "test_img, test_lbl = validation_generator.__next__()\n",
        "predictions = my_model.predict(test_img)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "test_labels = np.argmax(test_lbl, axis=1)\n",
        "\n",
        "# Calculating and printing the accuracy\n",
        "print(\"Accuracy =\", metrics.accuracy_score(test_labels, predictions))\n",
        "\n",
        "# Displaying the confusion matrix\n",
        "cm = metrics.confusion_matrix(test_labels, predictions)\n",
        "sns.heatmap(cm, annot=True)\n",
        "\n",
        "# Displaying a random image from the validation dataset with its original and predicted labels\n",
        "n = np.random.randint(0, test_img.shape[0])\n",
        "image = test_img[n]\n",
        "orig_labl = class_labels[test_labels[n]]\n",
        "pred_labl = class_labels[predictions[n]]\n",
        "plt.imshow(image[:, :, 0], cmap=\"gray\")\n",
        "plt.title(f\"Original label: {orig_labl} | Predicted: {pred_labl}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RILV9TVhxFGe"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "We successfully trained a deep learning model for facial emotion detection using the \"fer2013\" dataset. The model can classify facial emotions into seven categories with reasonable accuracy. Further improvements can be made by fine-tuning the model, using a larger dataset, or employing more advanced architectures.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
