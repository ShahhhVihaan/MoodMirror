{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/drive/My\\ Drive/data.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/content//data' # CHANGE\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "base_dir = os.path.join(base_dir, '..')\n",
    "base_dir = os.path.join(base_dir, 'data')\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "val_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21685 files belonging to 7 classes.\n",
      "Found 5906 files belonging to 7 classes.\n",
      "Found 7178 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(48, 48),\n",
    "    label_mode=\"categorical\",\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=(48, 48),\n",
    "    label_mode=\"categorical\",\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(48, 48),\n",
    "    label_mode=\"categorical\",\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dataset.take(1):\n",
    "    print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=128, learning_rate=3e-3, input_shape=(48, 48, 1)):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Rescaling(1./255))\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# Modify the KerasRegressorWrapper class to accept hyperparameters\n",
    "class KerasRegressorWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_hidden=1, n_neurons=200, learning_rate=1e-3):\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_neurons = n_neurons\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        self.model = build_model(self.n_hidden, self.n_neurons, self.learning_rate)\n",
    "        self.model.fit(X, y, **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, train, **kwargs):\n",
    "        self.model = build_model(self.n_hidden, self.n_neurons, self.learning_rate)\n",
    "        self.model.fit(train, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Create an instance of the KerasRegressorWrapper\n",
    "keras_reg = KerasRegressorWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_with_parameter_search.h5\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"),\n",
    "    keras.callbacks.EarlyStopping(patience=10)\n",
    "]\n",
    "\n",
    "param_distribs = {\n",
    "    # fill in code\n",
    "    \"n_hidden\": [0,1,2,3],\n",
    "    \"n_neurons\": np.arange(100, 300).tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=20, cv=3, verbose=2, n_jobs=-1)\n",
    "rnd_search_cv.fit(train_dataset, epochs=100,\n",
    "                  validation_data=validation_dataset,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "test_datagen = ImageDataGenerator()\n",
    "model = keras.models.load_model(\"convnet_with_parameter_search.h5\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(218, 178),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
